---
name: experience-capture
description: 此 Skill 在执行 /req、/plan 001、/build 001、/review 001、/init 等命令时自动激活，自动检测当前阶段和任务编号，提供统一的 EXP-CANDIDATE 捕获逻辑。
---

# Experience Capture

## Instructions

### 1. 阶段和任务编号检测逻辑

**统一检测策略：对话历史优先 + 文件验证补充**

采用分层检测策略，确保检测的准确性和可靠性：

**检测层级**（按优先级顺序）：

| 层级 | 检测方式   | 用途                   | 可靠性             |
| ---- | ---------- | ---------------------- | ------------------ |
| L1   | 对话历史   | 确定当前阶段和任务编号 | 高（唯一权威来源） |
| L2   | 文件存在性 | 验证任务状态、显示进度 | 中（辅助信息）     |
| L3   | 用户确认   | 兜底（历史缺失时）     | 高（用户明确指定） |

#### 1.1 L1：对话历史检测（主要来源）

1. 检测用户最近输入的命令（`/plan 001`、`/build 001`、`/review 001` 等）
2. 提取命令名（plan/build/review）和参数（001）
3. 命令名直接对应阶段：`/plan` → plan 阶段，`/build` → build 阶段，`/review` → review 阶段
4. 命令参数直接对应任务编号：`001` → 任务编号 001

**特殊命令**：

- `/req <描述>` → 阶段：req，任务编号：自动生成（待写入文件后确定）
- `/review-req 001` → 阶段：review-req，任务编号：001
- `/init` → 阶段：init，任务编号：null

#### 1.2 L2：文件存在性验证（辅助来源）

用于验证任务状态和显示任务进度，**不用于判断当前阶段**：

```
扫描 .cursor/.lingxi/requirements/ 目录：
- 001.req.*.md 存在 → 任务 001 已创建 req
- 001.plan.*.md 存在 → 任务 001 已创建 plan
- 001.testcase.*.md 存在 → 任务 001 已创建 testcase
```

**使用场景**：

- 执行 `/plan 001` 前验证 `001.req.*.md` 是否存在
- 显示任务进度（如 "任务 001：req ✅ plan ✅ build ⏳"）
- 提供任务状态概览

#### 1.3 L3：用户确认兜底

当对话历史缺失（如新会话）时：

- 提示用户明确指定任务编号
- 或通过命令参数获取（如 `/build 001`）

**为什么文件推断不能作为主要来源**：

- **并行任务切换**：用户可能在任务 001 和 002 之间切换，文件系统无法判断当前正在处理哪个任务
- **文件修改时间**：最近修改的文件可能是之前任务留下的，不代表当前任务
- **文件存在性**：文件存在性只能说明任务曾经执行过某个阶段，不能说明当前正在执行哪个阶段

### 2. 统一的 EXP-CANDIDATE 捕获逻辑

#### 2.1 触发机制

**核心原则**：只有用户拥有真正的判断力，经验来自用户的判断和确认。

**触发流程**：

每次用户输入时，执行以下扫描和捕获流程：

1. **用户直接经验扫描**
   - 分析用户输入的语义，判断是否包含经验信号（判断、取舍、边界、约束、规范、问题解决等）
   - 如果识别到经验信号 → 进入完整捕获流程

2. **用户确认 AI 建议扫描**
   - 结合上下文（最近的 AI 输出），分析用户输入是否在确认、采纳、接受 AI 的建议或风险
   - 典型确认信号：
     - 确认风险："接受这个风险"、"这个风险可以接受"
     - 采纳建议："采用方案 A"、"就用这个方案"、"好的，按这个来"
     - 确认问题："确实有问题，改成..."、"按你的建议修改"
   - 如果识别到用户确认 AI 建议 → 进入完整捕获流程
   - **不捕获**：AI 单独输出的风险、建议等，在用户确认前不捕获

3. **完整捕获流程**（当识别到经验信号时）
   - 自动检测当前阶段和任务编号（使用上述检测逻辑）
   - 基于语义理解识别经验类型和结构
   - 参考触发场景列表（`references/req-triggers.md`、`references/init-triggers.md` 等）帮助理解经验类型，但不作为限制
   - 生成 EXP-CANDIDATE JSON 对象
   - **输出用户友好的摘要并询问用户确认**（见 2.2 节）

**静默跳过**：如果未识别到经验信号，静默跳过，不执行捕获流程

**AI Native 原则**：
- 完全依赖 LLM 的自然语言理解能力，不进行关键词匹配
- 触发场景列表（`references/req-triggers.md` 等）仅作为参考，帮助理解经验类型和结构
- 不限制捕获范围，让 AI 根据语义理解灵活识别经验信号

#### 2.2 用户确认和评估流程

当生成 EXP-CANDIDATE 后，执行以下流程：

1. **输出用户友好的摘要**
   - 格式：`已识别 X 个经验候选：[候选1类型]、[候选2类型]、...`
   - 候选类型示例：架构决策、类型共享、依赖注入、SEO 优化等
   - 如果同时识别多个候选，汇总展示

2. **询问用户确认**
   ```markdown
   ## 请确认经验候选
   
   已识别 X 个经验候选：[候选1类型]、[候选2类型]、...
   
   - ✅ **A) 全部确认**：评估并暂存这些候选
   - 📝 **B) 需要调整**：请说明需要调整的候选和内容
   - ⏭️ **C) 跳过确认**：直接评估并暂存
   ```

3. **用户确认后的处理**
   - **如果用户选择 A 或 C**：
     - 调用 `candidate-evaluator` Skill，传递 EXP-CANDIDATE JSON 和 `stage1` 参数
     - 执行阶段 1 评估（结构完整性、判断结构质量、可复用性、沉淀载体适配性）
     - 如果评估通过，继续执行步骤 4
     - 如果评估不通过，记录过滤原因，不写入文件
   
   - **如果用户选择 B**：
     - 允许用户修改候选信息
     - 修改后重新展示候选列表，再次询问确认
     - 确认后执行评估和写入流程

4. **写入文件**
   - 读取 `.cursor/.lingxi/context/session/pending-compounding-candidates.json`（如果存在）
   - 如果文件不存在，创建新文件，初始化为：`{"candidates": [], "asked": false}`
   - 将评估通过的候选合并到 `candidates` 数组
   - 保留 `asked` 标志（如果已存在）
   - 为每个候选添加 `evaluation` 字段（阶段 1 的评估结果）
   - 为每个候选添加 `sourceStage` 字段（标识候选来源阶段）
   - 为每个候选添加时间戳
   - 写入文件

5. **输出确认信息**
   - 格式：`已识别并暂存 X 个经验候选`
   - 如果评估过滤了部分候选，说明过滤原因

**EXP-CANDIDATE JSON 格式**：

```json
{
  "taskId": "001",
  "stage": "plan",
  "trigger": "当任务 T2 依赖从A改为B",
  "decision": "任务/验收/测试策略的取舍",
  "alternatives": ["原方案A（放弃，因为...）"],
  "signal": "判断依据/风险信号",
  "solution": "新的任务拆解/验收/测试策略",
  "verify": "后续如何验证该决策",
  "pointers": ["path/to/plan-file 或相关模块"],
  "reqFile": ".cursor/.lingxi/requirements/001.req.<标题>.md",
  "notes": "可选补充"
}
```

**关键字段**：

- `taskId`：任务编号（001, 002, ...），对于 `/init` 命令设为 `null`
- `stage`：当前阶段（req/plan/build/review/init）
- `reqFile`：关联的 req 文件路径（用于后续匹配和追溯），对于 `/init` 命令设为 `null` 或省略

**对于 `/init` 命令的特殊处理**：

- `taskId`：设为 `null`（因为 `/init` 不关联具体任务）
- `stage`：设为 `init`
- `reqFile`：设为 `null` 或省略
- 其他字段正常填写


### 3. 捕获规则

#### 3.1 用户确认原则

- 捕获时输出用户友好的摘要，不输出技术细节（JSON 结构）
- 用户确认后才执行评估和写入文件
- 符合"人工门控"原则，关键决策遵从用户指引

#### 3.2 格式要求

- 必须包含所有关键字段（taskId, stage, trigger, decision, solution, verify, reqFile）
- alternatives 字段可选，但如果存在决策取舍，应包含至少一个备选方案
- pointers 字段应指向相关文件或模块，便于追溯

#### 3.3 质量要求

- 只捕获有价值的经验（有明确的触发条件、决策依据、解决方案）
- 避免捕获过于具体或临时的决策（无法复用的经验）
- 确保经验的通用性（可在类似场景下复用）
